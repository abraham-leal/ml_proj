{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98b092cf-735a-4441-bb10-937c736f50aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import wandb\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c81df0ae-41a8-4864-987a-fef06788b2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mableal\u001b[0m (\u001b[33mwandb-smle\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "#!wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7adef941-b8f5-4d7c-90d0-eecef8b41ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.386643</td>\n",
       "      <td>2.332162</td>\n",
       "      <td>0.643234</td>\n",
       "      <td>0.562390</td>\n",
       "      <td>0.390158</td>\n",
       "      <td>32.816680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.487409</td>\n",
       "      <td>0.830982</td>\n",
       "      <td>0.479466</td>\n",
       "      <td>1.176378</td>\n",
       "      <td>0.821568</td>\n",
       "      <td>51.304312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.458300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Survived      Pclass         Sex       SibSp       Parch        Fare\n",
       "count  569.000000  569.000000  569.000000  569.000000  569.000000  569.000000\n",
       "mean     0.386643    2.332162    0.643234    0.562390    0.390158   32.816680\n",
       "std      0.487409    0.830982    0.479466    1.176378    0.821568   51.304312\n",
       "min      0.000000    1.000000    0.000000    0.000000    0.000000    0.000000\n",
       "25%      0.000000    2.000000    0.000000    0.000000    0.000000    7.895800\n",
       "50%      0.000000    3.000000    1.000000    0.000000    0.000000   14.458300\n",
       "75%      1.000000    3.000000    1.000000    1.000000    0.000000   31.275000\n",
       "max      1.000000    3.000000    1.000000    8.000000    5.000000  512.329200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Mod data to fit model\n",
    "##### Drop \"Names\"\n",
    "##### Drop \"Cabin\"\n",
    "##### Drop \"PassengerId\"\n",
    "##### Drop \"Ticket\"\n",
    "##### Drop \"Embarked\"\n",
    "##### Numericalize \"Sex\"\n",
    "##### BUcketize \"Age\" and fillna\n",
    "##### Generate train/valid/test splits\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train_csv = pd.read_csv(\"./titanic/train.csv\", index_col='PassengerId')\n",
    "test_csv = pd.read_csv(\"./titanic/test.csv\", index_col='PassengerId')\n",
    "train_csv = train_csv.drop('Name', axis=1)\n",
    "train_csv = train_csv.drop('Cabin', axis=1)\n",
    "train_csv = train_csv.drop('Ticket', axis=1)\n",
    "train_csv = train_csv.drop('Embarked', axis=1)\n",
    "train_csv['Sex'] = train_csv['Sex'].astype('category')\n",
    "train_csv['Sex'] = train_csv['Sex'].cat.codes\n",
    "bins= [0,18,40,60,100]\n",
    "labels = [0,1,2,3]\n",
    "train_csv['Age'] = train_csv['Age'].fillna(train_csv['Age'].mean())\n",
    "train_csv['Age'] = pd.cut(train_csv['Age'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "train, test = train_test_split(train_csv, test_size=0.2)\n",
    "train, valid = train_test_split(train, test_size=0.2)\n",
    "\n",
    "train.describe()\n",
    "### Now we have train, validation, and test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb0564e6-e8bf-4ad8-b5bb-8b9415804f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mableal\u001b[0m (\u001b[33mwandb-smle\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "fatal: ambiguous argument 'HEAD': unknown revision or path not in the working tree.\n",
      "Use '--' to separate paths from revisions, like this:\n",
      "'git <command> [<revision>...] -- [<file>...]'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/abrahamleal/Documents/git/mlPreso/mlPreso/wandb/run-20240709_155012-claa31zw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wandb-smle/aleal-kaggle-titanic/runs/claa31zw' target=\"_blank\">swept-sky-21</a></strong> to <a href='https://wandb.ai/wandb-smle/aleal-kaggle-titanic' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wandb-smle/aleal-kaggle-titanic' target=\"_blank\">https://wandb.ai/wandb-smle/aleal-kaggle-titanic</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wandb-smle/aleal-kaggle-titanic/runs/claa31zw' target=\"_blank\">https://wandb.ai/wandb-smle/aleal-kaggle-titanic/runs/claa31zw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Initialize this run\n",
    "config = { 'batchSize': 64, 'num_epochs': 100, 'lr': 0.01}\n",
    "\n",
    "run = wandb.init(entity=\"wandb-smle\",\n",
    "        project=\"aleal-kaggle-titanic\", save_code=True,\n",
    "                 group=\"debug\", force=True, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a4741a2-a0dc-43c8-8214-e26db3ead712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Artifact titatinc_artifacts>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save source data to W&B\n",
    "test_table = wandb.Table(dataframe=test_csv)\n",
    "train_table = wandb.Table(dataframe=train_csv)\n",
    "data_art = wandb.Artifact(name=\"titatinc_artifacts\", type=\"dataset\")\n",
    "data_art.add_file(\"./titanic/train.csv\")\n",
    "data_art.add_file(\"./titanic/test.csv\")\n",
    "data_art.add(train_table, \"train_table\")\n",
    "data_art.add(test_table, \"test_table\")\n",
    "\n",
    "run.log_artifact(data_art)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14c5ab2d-5594-49d3-92fe-ae7acb9d1f80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy\n",
    "\n",
    "class CustomTitanicDataset(Dataset):\n",
    "    def __init__(self, df, transform=None, target_transform=None):\n",
    "        self.data: pd.DataFrame\n",
    "        self.data = df\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        row = self.data.iloc[idx]\n",
    "            \n",
    "        datapoint = torch.tensor(row.iloc[1:7].values, dtype=torch.float32)\n",
    "        label = torch.tensor(row.iloc[0], dtype=torch.float32)\n",
    "        \n",
    "        if self.transform:\n",
    "            dp = self.transform(datapoint)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "\n",
    "        return datapoint, label\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "\n",
    "device=torch.device(\"cpu\")\n",
    "\n",
    "class binaryModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(binaryModel, self).__init__()\n",
    "        self.hidden = nn.Linear(6, 100)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.output = nn.Linear(100, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.hidden(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.output(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "model = binaryModel()\n",
    "\n",
    "model.to(device)\n",
    "run.watch(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21c20dfc-9992-4f6a-b981-f087836b4894",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Trainer\n",
    "import torch.utils.data\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "train_ds = CustomTitanicDataset(train)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_ds, batch_size=run.config.batchSize, shuffle=True)\n",
    "\n",
    "valid_ds = CustomTitanicDataset(valid)\n",
    "valid_dataloader = torch.utils.data.DataLoader(valid_ds, batch_size=run.config.batchSize, shuffle=True)\n",
    "\n",
    "test_ds = CustomTitanicDataset(test)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "602e8583-d241-4d05-9faf-77fc01a158f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training and Validation Loop\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "loss_fn = loss_fn.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=run.config.lr)\n",
    "\n",
    "for epoch in range(run.config.num_epochs):\n",
    "    train_total_correct = 0\n",
    "    train_total_samples = 0\n",
    "    train_running_loss = 0\n",
    "\n",
    "    valid_total_correct = 0\n",
    "    valid_total_samples = 0\n",
    "    valid_running_loss = 0\n",
    "    \n",
    "    model.train()\n",
    "    for idx, (data, label) in enumerate(train_dataloader):\n",
    "        data.to(device)\n",
    "        label.to(device)\n",
    "        \n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, label.unsqueeze(1))\n",
    "        optimizer.zero_grad()\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_total_correct += (predicted == label).sum().item()\n",
    "        train_total_samples += label.size(0)\n",
    "        train_running_loss += loss.item()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx, (data, label) in enumerate(valid_dataloader):\n",
    "            data.to(device)\n",
    "            label.to(device)\n",
    "            \n",
    "            output = model(data)\n",
    "            loss = loss_fn(output, label.unsqueeze(1))\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            \n",
    "            valid_total_correct += (predicted == label).sum().item()\n",
    "            valid_total_samples += label.size(0)\n",
    "            valid_running_loss += loss.item()\n",
    "\n",
    "    train_accuracy = train_total_correct / train_total_samples\n",
    "    train_loss = train_running_loss / len(train_ds)\n",
    "    valid_accuracy = valid_total_correct / valid_total_samples\n",
    "    valid_loss = valid_running_loss / len(valid_ds)\n",
    "    run.log({\"train_acc\": train_accuracy, \"train_loss\": train_loss}, step=epoch)\n",
    "    run.log({\"valid_acc\": valid_accuracy, \"valid_loss\": valid_loss}, step=epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2384d92d-3996-425a-ae32-cbe873491e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output_table = wandb.Table(columns=[\"Id\", \"In_Pclass\", \"In_Sex\", \"In_SibSp\", \"In_Parch\", \n",
    "                                         \"In_Fare\", \"Prediction\", \"Ground_Truth\", \"Pred_Probability\"])\n",
    "\n",
    "total_correct = 0\n",
    "total_tests = 0\n",
    "\n",
    "for idx, (data, label) in enumerate(test_dataloader):\n",
    "    data.to(device)\n",
    "    label.to(device)\n",
    "\n",
    "    output = model(data)\n",
    "    prediction = output.squeeze(dim=0).item()\n",
    "    total_tests += 1\n",
    "\n",
    "    num_pred = 0\n",
    "    prob = 0\n",
    "\n",
    "    if (prediction > 0.5):\n",
    "        num_pred = 1\n",
    "        prob = prediction\n",
    "    else:\n",
    "        prob = 1-prediction\n",
    "\n",
    "    curr_row = test.iloc[idx]\n",
    "    test_output_table.add_data(idx, curr_row['Pclass'], curr_row['Sex'], curr_row['SibSp']\n",
    "                              , curr_row['Parch'], curr_row['Fare'], num_pred, curr_row['Survived'], prob)\n",
    "\n",
    "    if (num_pred == curr_row['Survived']):\n",
    "        total_correct += 1\n",
    "    \n",
    "run.log({\"test_acc\": total_correct / total_tests})\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c2b8199-4cde-4ce6-969c-a468918d7774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e9869d5cd7c44e5995946cf57ed731f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.076 MB of 0.076 MB uploaded (0.020 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 21.6%             "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_acc</td><td>▁</td></tr><tr><td>train_acc</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▂▁▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid_acc</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid_loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_acc</td><td>0.79888</td></tr><tr><td>train_acc</td><td>0.61336</td></tr><tr><td>train_loss</td><td>0.00665</td></tr><tr><td>valid_acc</td><td>0.63636</td></tr><tr><td>valid_loss</td><td>0.00915</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">swept-sky-21</strong> at: <a href='https://wandb.ai/wandb-smle/aleal-kaggle-titanic/runs/claa31zw' target=\"_blank\">https://wandb.ai/wandb-smle/aleal-kaggle-titanic/runs/claa31zw</a><br/> View project at: <a href='https://wandb.ai/wandb-smle/aleal-kaggle-titanic' target=\"_blank\">https://wandb.ai/wandb-smle/aleal-kaggle-titanic</a><br/>Synced 4 W&B file(s), 1 media file(s), 6 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240709_155012-claa31zw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run.log({\"predictions_table\": test_output_table})\n",
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
